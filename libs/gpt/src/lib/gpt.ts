// import { User, Message } from '@libs/dynamo-db'; // TODO: make this work
import {
  generateUserInfo,
  appendMessageHistory,
  systemPrompt,
  exerciseUtilSystemPrompt,
} from './utils';
import { executeGPTModel } from './execute-gpt';
import OpenAI from 'openai';

let openaiClient: OpenAI;

/**
 * Initializes the OpenAI client with an initial system prompt
 */
export async function gptSetup() {
  openaiClient = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });
}

/**
 * @description Uses the OpenAI API to generate a response to a user input. The function takes in a text input from the user and sends it to the OpenAI API as a message. The API returns a completion that includes a response generated by the GPT-4 model.
 * @returns chat completion response
 */
export async function gptChatResponse(
  prompt: string,
  // messageHistory?: Message[],  // TODO: make this work
  // user?: User
  messageHistory?: any,
  user?: any
) {
  if (!openaiClient) {
    console.log('GPT not setup yet! Initialize Gpt model...');
    await gptSetup();
    console.log('Done with GPT setup');
  }

  let scopedSystemPrompt = systemPrompt;
  if (user) {
    const userPrompt = generateUserInfo(user);
    if (userPrompt.length > 0) {
      //console.log(userPrompt);
      scopedSystemPrompt = scopedSystemPrompt + '\n\n' + userPrompt;
    }
  }

  // We feed this to the GPT prompt
  const messages = [
    {
      role: 'system',
      content: scopedSystemPrompt,
    },
  ];
  if (messageHistory) {
    appendMessageHistory(messageHistory, messages);
  }

  const completion = await executeGPTModel(messages, openaiClient, prompt);

  // console.log(completion.choices[0].message.content);
  return completion;
}

/**
 * Interprets the stress level of a user based on their message history. The function uses the OpenAI API to generate a response to a user input and to interpret the response to determine the user's stress level.
 * @param user The user object
 * @param prompt The current user prompt
 * @param messageHistory Message history of user and GPT model
 * @returns
 */
export async function interpretStressLevel(
  user: any,
  prompt: any,
  messageHistory?: any
) {
  console.log('calling user profile adjustment');

  const systemPrompt = `Analyse the user's stress level by checking his message history. Evaluate the stress level with using a metric between -1 and 1, whereas -1 is depressed and 1 is cheerful. Please answer with a single number. Most recent messages have a bigger significance than older messages.`;
  const messages = [
    {
      role: 'system',
      content: systemPrompt,
    },
  ];

  if (messageHistory) {
    appendMessageHistory(messageHistory, messages);
  }

  const score = await executeGPTModel(messages, openaiClient, prompt);

  const newUser = { ...user };
  if (!isNaN(+score)) {
    // check if a score was actually created
    newUser.stressScore = Number(+score);
  }
  console.log('Score: ', score);

  return newUser;
}

export async function gptExerciseResponse(
  prompt: string,
  messageHistory: any,
  user: any,
  exercise: any
) {
  if (!openaiClient) {
    console.log('GPT not setup yet! Initialize Gpt model...');
    await gptSetup();
    console.log('Done with GPT setup');
  }

  let scopedSystemPrompt = systemPrompt;
  const userInfo = generateUserInfo(user);
  console.log(user.exerciseStep, exercise.questions[user.exerciseStep + 1]);
  if (userInfo.length > 0) {
    scopedSystemPrompt = scopedSystemPrompt + '\n\n' + userInfo;
  }
  const exercisePrompt = exercise.questions[user.exerciseStep + 1];
  scopedSystemPrompt =
    scopedSystemPrompt + exerciseUtilSystemPrompt + exercisePrompt;

  // We feed this to the GPT prompt
  const messages = [
    {
      role: 'system',
      content: scopedSystemPrompt,
    },
  ];

  let exerciseMessageHistory;
  if (user.exerciseStep > 0) {
    exerciseMessageHistory = messageHistory.slice(user.exerciseStep * -1);
    if (messageHistory) {
      appendMessageHistory(exerciseMessageHistory, messages);
    }
  }

  const completion = await executeGPTModel(messages, openaiClient, prompt);
  return completion;
}
